\documentclass{exam}
\usepackage{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{ragged2e}
\usepackage{blindtext}
\usepackage{lmodern}
\usepackage{tcolorbox}
\usepackage{hyperref}

\pagestyle{empty}
\renewcommand{\theenumi}{\alph{enumi}} 

\DeclareMathOperator*{\argmin}{arg\,min}

\begin{document}

\begin{center}
    \textbf{\Large Exercises 2.5}    
\end{center}

\section*{Exercise 2.5.1}
\begin{enumerate}
    \item Show that the logistic function $\sigma$ satisfies the inequality $ 0 < \sigma^{\prime}(x) \leq \frac{1}{4}$, for all $x \in \mathbb{R}$.
    \item How does the inequality changes in the case of the functions $\sigma_{c}$?
\end{enumerate}  

\section*{Exercise 2.5.2}
Let $S(x)$ and $H(x)$ denote the bipolar step fucntion and the Heaviside function, respectively. Show that: \\
\begin{enumerate}
    \item $S(x) = 2H(x) - 1 $
    \item $ReLU(x) = \frac{1}{2}x(S(x) + 1)$
\end{enumerate}
\section*{Exercise 2.5.3}
Show that the softplus function, $sp(x)$, satisfies the following properties:
\begin{enumerate}
    \item $sp^\prime(x) = \sigma(x)\text{, where } \sigma(x) = \frac{1}{1 + e^{-x}}$
    \item Show that $sp(x)$ is invertible with inverse $sp^{-1}(x) = \text{ln}(e^x - 1)$
    \item Use the softplus function to show the formula $\sigma(x) = 1 - \sigma(-x)$
\end{enumerate}

\section*{Exercise 2.5.4}
Show that $\text{tanh}(x) = 2\sigma(2x) - 1 $

\section*{Exercise 2.5.5}
Show that the softsign function, $so(x)$, satisfies the following properties:
\begin{enumerate}
    \item Its sctrictly increasing;
    \item Its is onto $(-1,1)$, with the inverse $so^{-1}(x) = \frac{x}{1 - |x|}$, for $|x| < 1$.
    \item $so(|x|)$ is subadditive, i.e., $so(|x+y|) \leq so(|x|) + so(|y|)$. 
\end{enumerate}

\section*{Exercise 2.5.6}
Show that the softmax function is invariant with respect to the addition of constant vectors $\pmb{c} = (c_1 \ldots c_n)^{T}$, i.e., \\
\begin{equation*}
    softmax(y + \pmb{c}) = softmax(y).
\end{equation*}\\
This property is used in practice by replacing $\pmb{c} = - \text{max}_i y_i$, fact that leads to a more stable numerically variant of this function.

\section*{Exercise 2.5.7}
Let $\rho: \mathbb{R}^n \rightarrow \mathbb{R}^n$ defined by $\rho(y) \in \mathbb{R}^n$, with $\rho(y)_i = \frac{y^2_i}{\lVert y \rVert }$. Show that: 
\begin{enumerate}
    \item $0 \leq \rho(y)_i \leq 1$ and $\sum_i \rho(y)_i = 1$.
    \item The function $\rho$ is invariant with to multiplication by nonzero constant, i.e., $\rho(\lambda y ) = \rho(y)$ for any $\lambda \in \mathbb{R}/{0}$. Taking $\lambda = \frac{1}{\text{max}_i y_i}$ leads in practice to a more stable version of this function. 
\end{enumerate}

\section*{Exercise 2.5.8 (cosine squasher)}
Show that the function $\varphi(x) = \frac{1}{2}(1 + \text{cos}(x + \frac{3\pi}{2}))1_{\tiny [-\frac{\pi}{2}, \frac{\pi}{2}]}(x) + 1_{\tiny (\frac{\pi}{2}, \infty)}(x)$ is a 
squashing function.

\section*{Exercise 2.5.9}
\begin{enumerate}
    \item Show that any squashing function is a sigmoidal function.
    \item Give an example of a sigmoidal function which is not a squashing function.
\end{enumerate}

\newpage

\begin{center}    
    \section*{SOLUTIONS}
\end{center}

\subsection*{2.5.1 (a)}
Computing the derivative of $\sigma$ we find: $\sigma^\prime(x) = \frac{d}{dx} \frac{1}{ 1 + e^{-x}} = \frac{d}{dx} \frac{e^x}{ 1 + e^{x}} = \frac{e^x}{(1 + e^{x})^2}$. From the inequality $1 \leq (1+e^x)^2$ and the non-negativeness of the exponential function follows that 
$0 \leq \frac{e^x}{(1 + e^{x})^2}$. \\
\\
Now lets prove that in $x=0$ the function has a local maximum in $[-1,1]$, this will imply $0 \leq \frac{e^x}{(1 + e^{x})^2} \leq \sigma^\prime(0)$, $\sigma^\prime(0) = \frac{1}{4}$. By computing the first derivative of $\sigma^\prime$ we find: 
$\sigma^{\prime\prime}(x) = e^{x}\frac{1-e^{x}}{(1 + e^{x})^3}$. The critical will be found by solving the equation $\sigma^{\prime\prime}(x) = 0$. \\
\\
From $\sigma^{\prime\prime}(x) = e^{x}\frac{1-e^{x}}{(1 + e^{x})^3} = 0$ follows that $1 - e^x = 0$, is straigth-forward to check that \\
the solution is $x=0$. It rests to determine the nature of the extremizing point. To achieve this goal is necessary to calculate the second derivative of $\sigma^{\prime}$.
\begin{equation*}     
        \begin{aligned}
            \sigma^{\prime\prime\prime}(x) &= \frac{d}{ d x} \frac{e^{x}-e^{2x}}{(1 + e^{x})^3} = \frac{(e^x - 2e^{2x})(1 + e^x)^3 - 3(1 + e^x)^2 e^{x}(e^x - e^{2x})}{(1 + e^x)^6}\\
            &= \frac{e^{x} \{ 1 - 4e^x + e^{2x} \}(1 + e^x)^2}{(1 + e^x)^{6}} = \frac{e^{x} \{ 1 - 4e^x + e^{2x} \}}{(1 + e^x)^{4}}
        \end{aligned}
\end{equation*}
\\
We clearly have $\sigma^{\prime\prime\prime}(0) < 0$, then $x = 0$ is a local maximum for $\sigma^\prime$, i.e $\forall x \in [-1, 1], \ \sigma^\prime(x) \leq \frac{1}{4}$. On the other hand,
the function $\sigma^\prime$ decreases on the intervals $(-\infty,-1)$ and $(1, \infty)$ this implies that:\\
\\
$\displaystyle\sup_{x \in (1,\infty)}\sigma^{\prime}(x) = \displaystyle\frac{e}{(1 + e)^2} = \displaystyle\frac{e^{-1}}{(1 + e^{-1})^2} = \sup_{x \in (-\infty,-1)} \sigma^{\prime}(x)$.
From the fact that $\displaystyle\frac{e}{(1 + e)^2} < \frac{1}{4}$ follows that $ 0 \leq \sigma^\prime(x) \leq \frac{1}{4}$ is valid $\forall x \in \mathbb{R}. \text{ \ \qedsymbol{}}$\\

\subsection*{2.5.1 (b)}
The inequality changes to: $ 0 \leq \sigma^\prime_c(x) \leq \frac{c}{4}, \ \forall x \in \mathbb{R}$. From the expression $\sigma_c(x) = \frac{1}{1 + e^{-cx}}$, $c > 0$ one finds that $\sigma^{\prime}_c(x) = \frac{d}{d x} \frac{e^{cx}}{1 + e^{cx}} = \displaystyle c \frac{e^{cx}}{(1 + e^{cx})^2}$. By the chain rule it can be easily verified that all the computations 
made for $\sigma^{\prime}(x)$ in 2.5.1.a, can by applied to $\sigma^{\prime}_c(x)$, having in mind the relationship $\sigma^{\prime}_c(x) = c \sigma^{\prime}(cx)$. \\
\\
Then, one finds: $\sigma^{\prime\prime}_c(x) = c^{2} e^{cx}\frac{1-e^{cx}}{(1 + e^{cx})^3}$, this implies that $x=0$ is a critical point. Using the same relationship is clear that $\sigma^{\prime\prime\prime}_c(x) \Big|_{x=0} = c^{3}\frac{e^{cx} \{ 1 - 4e^{cx} + e^{2cx} \}}{(1 + e^{cx})^{4}} \Big|_{x=0} < 0$. Then, $x=0$ is a maximum. \\
\\
Arguing like in 2.5.1.a, on the interval $[-1,1]$, $\sigma^{\prime}_c(0) = \frac{c}{4}$ is a local maximum. More over, the function $\sigma^\prime_c$ decreases on the intervals
$(-\infty,-1)$ and $(1, \infty)$, implying: \newline
\begin{equation*}
    \displaystyle\sup_{x \in (1,\infty)}\sigma^{\prime}_c(x) = \displaystyle\frac{ce^{c}}{(1 + e^{c})^2} = \displaystyle\frac{ce^{-c}}{(1 + e^{-c})^2} = \sup_{x \in (-\infty,-1)} \sigma^{\prime}_c(x)
\end{equation*}
\newline
Lets now prove the inequality $ \displaystyle\frac{ce^{c}}{(1 + e^{c})^2} < \frac{c}{4}$. We have: 
\begin{equation*}
    \begin{aligned}
        \displaystyle\frac{ce^{c}}{(1 + e^{c})^2} &= \displaystyle\frac{c}{\frac{(1 + e^{c})^2}{\displaystyle e^{\frac{2c}{2}}}} = \displaystyle\frac{c}{(\frac{1 + e^{c}}{\displaystyle e^{\frac{c}{2}}})^2}\\
        &= \displaystyle \frac{c}{(e^{-\frac{c}{2}} + e^{\frac{c}{2}})^2} < \displaystyle \frac{c}{(1 - \frac{c}{2} + 1 + \frac{c}{2})^2} = \frac{c}{4}
    \end{aligned}
\end{equation*}
Where we have used the inequality $1 + x \leq e^x, \ \forall x \in \mathbb{R}$. The later shows $\sigma^{\prime}_c(0)$ is a global maximum, \newline 
i.e $0 \leq \sigma^\prime_c(x) \leq \frac{c}{4}$ is valid $\forall x \in \mathbb{R}. \text{ \ \qedsymbol{}}$

\subsection*{2.5.2 (a)}
From the Heaviside function definition one has: 
\begin{equation*}
    \begin{aligned}
        2H(x) -1 &= 
        \left\{
        \begin{aligned}
            &2 - 1 \text{ if } x > 0 \\
            &2(0)-1 \text{ otherwise}
        \end{aligned}
        \right. \\
        &= \left\{
            \begin{aligned}
                &1 \text{ if } x > 0 \\
                &-1 \text{ otherwise}
            \end{aligned}
        \right. \ 
        = S(x). \text{ \ \qedsymbol{}}
    \end{aligned}    
\end{equation*}

\subsection*{2.5.2 (b)}
We know $ReLU(X):= \text{max}(0,x)$. Consider the identities $\text{max}(0,x) = \frac{1}{2} \{ x + |x| \}$, \\
\begin{equation*}
    |x| = 
    \begin{aligned}
        \left\{
        \begin{aligned}
            &1 x \text{ if } x > 0 \\
            &-1 x \text{ otherwise}
        \end{aligned}
        \right. = x S(x) \text{. Substituting the last identity into the first one yields: }
    \end{aligned}
\end{equation*}
$ReLU(x) = \frac{1}{2}(x + x S(x)) = \frac{1}{2}x(1 + S(x)). \ \qedsymbol{}$

\subsection*{2.5.3 (a)}
The identity inmeadiatly follows from the application of the chain rule to the function $\text{ln}(1 + e^x)$. In fact, we have: 
$sp^\prime(x) = \frac{d}{d x }\text{ln}(1 + e^x) = \frac{e^x}{1 + e^x} = \frac{1}{1 + e^{-x}}. \ \qedsymbol{}$

\subsection*{2.5.3 (b)}
The function $e^x$ is well known to never be zero, then $1 + e^x > 0, \forall x \in \mathbb{R}$. This implies $sp^{\prime}(x) \neq 0, \forall x \in \mathbb{R}$. Then by the \href{https://en.wikipedia.org/wiki/Inverse_function_theorem}{inverse function theorem} the function is 
invertible. We can now compute its inverse, which is given by:
\begin{equation*}
    sp(x) = y = \text{ln}(e^x + 1 ) \implies e^y = e^x + 1 \implies x = sp^{-1}(y) = \text{ln}(e^y - 1). \ \qedsymbol{}
\end{equation*}

\subsection*{2.5.3 (c)}
Let $F(x) :=  x + sp(-x) - sp(x)$. It happens that derivative of $F$ is 0, then by the chain rule, the linearity of the derivative operator and the relationship 
proved in 2.5.3.a yield: \newline
\\
$\frac{d}{d x } \left[ x + sp(-x) \right] = 1 - \sigma(-x) = \frac{d}{d x}sp(x) = \sigma(x)$. Lets now prove the claim aforementioned to complete the proof. We have: 
\begin{equation*}
    \begin{aligned}
        \frac{d}{d x } F(x) &= \frac{d}{d x } \left[ x + sp(-x) - sp(x)\right] = \frac{d}{d x } \left[ x + \text{ln}(\frac{e^{-x} + 1 }{e^x + 1})\right]\\
         &= 1 + \frac{e^x + 1 }{e^{-x} + 1}\frac{d}{d x }\left[\frac{e^{-x} + 1 }{e^{x} + 1}\right] = 1 + \frac{e^x + 1 }{e^{-x} + 1}\frac{-e^{-x}(e^x + 1) - e^x(1 + e^{-x})}{(e^{x} + 1)^2}\\
         &= 1 + \frac{e^x + 1 }{e^{-x} + 1}\frac{-e^{-x}(e^x + 1) - (1 + e^{x})}{(e^{x} + 1)^2} = 1 + \frac{e^x + 1 }{e^{-x} + 1}\frac{-(e^x + 1)(1 + e^{x})}{(e^{x} + 1)^2} = 1 - 1 = 0. \text{\ \ \qedsymbol{}}
    \end{aligned}
\end{equation*}

\subsection*{2.5.4 (a)}

\end{document} 