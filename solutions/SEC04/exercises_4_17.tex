\documentclass{exam}
\usepackage{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{ragged2e}
\usepackage{lmodern}
\usepackage{tcolorbox}
\usepackage{hyperref}
\usepackage{verbatim}

\pagestyle{empty}
\renewcommand{\theenumi}{\alph{enumi}}
\renewenvironment{proof}{{\noindent\itshape\ignorespaces}}{{\hfill$\qed$\\}}

\DeclareMathOperator*{\argmin}{arg\,min}

\begin{document}

\begin{center}
    \textbf{\Large Exercises 4.17 }
\end{center}

\section*{Exercise 4.17.1}
Let $f(x_1,x_2) = e^{x_1}\sin(x_2)$, with $(x_1,x_2) \in (0,1) \times (0,\frac{\pi}{2})$.
\begin{enumerate}
    \item Show that $f$ is a harmonic function;
    \item Find $\lVert \nabla f \lVert$;
    \item Show that the equation $\nabla f = 0$ does not have any solutions;
    \item Find the maxima and minima for the function $f$.
\end{enumerate}

\section*{Exercise 4.17.2}
Consider the quadratic function $Q(\bold{x}) = \frac{1}{2} \bold{x}^{T} A \bold{x} - b \bold{x}$, with A nonsingular square matrix of order $n$.
\begin{enumerate}
    \item Find the gradient $\lVert \nabla Q \lVert$;
    \item Write the gradient descent iteration;
    \item Find the Hessian $H_{Q}$;
    \item Write the iteration by Newton's formula and compute its limit.
\end{enumerate}

\section*{Exercise 4.17.3}
Let A be a nonsingular square matrix of order $n$ and $b \in \mathbb{R}^{n}$ a given vector. Consider the linear system $A\bold{x} = b$. The solution can be approximated using 
the following steps:\\
\begin{enumerate}
    \item Associate the cost function $C(\bold{x}) = \frac{1}{2} \lVert A \bold{x} - b \lVert^{2}.$ Find its gradient, $\nabla C(\bold{x})$,
    and Hessian $H_{C}(\bold{x})$;
    \item Write the gradient descent algorithm iteration which converges to the system solution $\bold{x}$ with the inital value $\bold{x}^{0} = 0$;
    \item Write Newton's iteration which converges to the system solution $\bold{x}$ with the initial value $\bold{x}^{0} = 0$.
\end{enumerate}

\section*{Exercise 4.17.4}
\begin{enumerate}
   \item Let $(a_n)_{n}$ be a sequence with $a_0 > 0$ satisfying the inequality \\
   $a_{n+1} \leq \mu a_n + K, \ \forall n \geq 1$, with $\mu \in (0,1)$ and $K > 0$. Show that the sequence $(a_n)_{n}$ is bounded from above.
   \item Consider the momentum method equations $(4.4.16)-(4.4.17)$, and asume that the function $f$ has a bounded gradient $\lVert \nabla f \lVert \leq M$. Show that the 
   sequence of velocities, $(v^n)_{n}$ is bounded.
\end{enumerate}

\section*{Exercise 4.17.5}
\begin{enumerate}
   \item  Let $f$ and $g$ two integrable functions. Verify that
            \begin{equation*}
                \int (f \star g) (x) d x  = \displaystyle \int f(x) d x \displaystyle \int g(x) d x 
            \end{equation*}

    \item Show that $\lVert f \star g \lVert \leq {\lVert f \lVert}_{1} {\lVert g \lVert}_{1}$
    \item Let $f_{\sigma} := g \star G_{\sigma}$ where $G_{\sigma} = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{x^{2}}{2\sigma^{2}}}$. Prove that ${\lVert f_{\sigma}\lVert}_{1} \leq {\lVert f \lVert}_{1}$ for $\sigma > 0$
\end{enumerate}

\section*{Exercise 4.17.6}
Show that the convolution of two Gaussians is also a Gaussian:\\
\begin{equation*}
    G_{\sigma_{1}} \star G_{\sigma_{2}} = G_{\sigma} \text{, where } \sigma = \sqrt{\sigma_1^{2} + \sigma_2^{2}}.
\end{equation*}

\section*{Exercise 4.17.7}
Show that the if $n$ have the sum equal to s,
\begin{equation*}
    \sigma_{1} + \ldots + \sigma_{n} = s,
\end{equation*}
then the numbers for which the sum of their squares, $\sum_{j=1}^{n} \sigma_{j}^{2}$, its minimum occurs for the case when all the numbers are equal to $\frac{s}{n}.$

\newpage

\begin{center}    
    \section*{SOLUTIONS}
\end{center}

\subsection*{Exercise 4.17.1 (a)}
    By definition a function is harmonic when satisffies the condition $\nabla^{2}f = 0$. Let's corroborate this is indeed fullfilied by the function 
    $f(x_1,x_2) = e^{x_1}\sin(x_2)$. For $\frac{\partial^{2}}{ \partial x^{2}_1}f$ and $\frac{\partial^{2}}{ \partial x^{2}_2}f$ we have:\\
    \begin{proof}
        \begin{equation*}     
            \begin{aligned}
                \frac{\partial^{2}}{ \partial x^{2}_1} e^{x_1}\sin(x_2) &=  \sin(x_2)\frac{\partial^{2}}{ \partial x^{2}_1} e^{x_1} = e^{x_1}\sin(x_2)\\
                \frac{\partial^{2}}{ \partial x^{2}_2} e^{x_1}\sin(x_2) &=  e^{x_1}\frac{\partial^{2}}{ \partial x^{2}_2}\sin(x_2)  = -e^{x_1}\sin(x_2)\\
            \end{aligned}
    \end{equation*}
    From the latter follows $\nabla^{2}f = \displaystyle\frac{\partial^{2}}{ \partial x^{2}_1}f + \displaystyle\frac{\partial^{2}}{ \partial x^{2}_2}f = 0$ i.e the function $f$ is harmonic.
    \end{proof}
\subsection*{Exercise 4.17.1 (b)}
By the pythagorean identity between the trigonometric functions $\sin$ and $\cos$ follows:\\
\begin{equation*}
    \lVert \nabla f \lVert = \sqrt{\nabla f \cdot \nabla f} = \sqrt{(e^{x_1}\cos(x_2))^{2} + (e^{x_1}\sin{x_2})^{2}} = e^{x_1}
\end{equation*}

\begin{comment}
    
    \subsection*{Exercise x.y.2 (a)}
    Et harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est 
    eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, 
    omnis dolor repellendus. 
    \begin{proof}
         a = a
    \end{proof}
\end{comment}
\end{document}